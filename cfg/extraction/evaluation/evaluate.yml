# STIndex Evaluation Configuration
# Configuration for running evaluations on datasets

# LLM Configuration
llm:
  # LLM Provider Selection
  # Options: hf, openai, anthropic
  llm_provider: hf

# Evaluation Configuration
evaluation:
  # Input dataset path (relative to project root or absolute)
  dataset_path: "data/input/eval_dataset_100.json"

  # Output directory for results (relative to project root or absolute)
  output_dir: "data/output/evaluations"

  # Sample limit (null for all samples)
  sample_limit: null

  # Resume from last checkpoint (looks for incomplete CSV in output_dir)
  resume: true

  # Batch processing mode
  # - false: Process items one-by-one (default, safer, works with all providers)
  # - true: Process items in batches using LLM batch API (faster with multi-GPU)
  batch_mode: true

  # Batch size for batch_mode=true (how many items to send to LLM at once)
  # Recommended: 10-50 for multi-GPU, lower for single GPU
  batch_size: 10

  # Save intermediate results every N samples (for fault tolerance)
  checkpoint_interval: 10

  # Match mode for spatial entities: "exact" or "fuzzy" (default: fuzzy)
  # - "exact": Exact match of location text
  # - "fuzzy": Substring or word overlap >= 50% (RECOMMENDED)
  # Note: Temporal matching always uses "value_exact" mode (compares ISO 8601 values)
  spatial_match_mode: "fuzzy"

  # Geocoding distance threshold for accuracy calculation (in km)
  geocoding_threshold_km: 25

# Output Configuration
output:
  # CSV column order and naming (predictions next to ground truth for easy comparison)
  csv_columns:
    - id
    - input_text
    # Temporal results
    - temporal_predicted
    - temporal_ground_truth
    - temporal_precision
    - temporal_recall
    - temporal_f1
    - temporal_normalization_accuracy
    # Spatial results
    - spatial_predicted
    - spatial_ground_truth
    - spatial_precision
    - spatial_recall
    - spatial_f1
    - spatial_geocoding_success_rate
    - spatial_mean_distance_error_km
    - spatial_accuracy_within_25km
    # Processing metadata
    - processing_time_seconds
    - error
    - llm_raw_output

  # Save detailed metrics summary JSON alongside CSV
  save_summary: true

  # Save final aggregated metrics
  save_aggregated_metrics: true
