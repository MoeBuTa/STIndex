# Corpus Extraction Configuration - Parallel Processing
# Worker-specific parameters (offset, limit, worker_id) passed as CLI arguments
#
# Usage:
#   python -m stindex.exe.extract_corpus \
#     --config cfg/extraction/corpus_extraction_parallel.yml \
#     --worker-id 1 --offset 0 --limit 1000 --num-gpus 4

input:
  corpus_path: "data/original/medcorp/train_textbooks_only.jsonl"

extraction:
  dimension_config: "data/schema_discovery_textbook_filtered/extraction_schema"  # Slim schema (64 dims, 14KB)
  batch_size: 100
  sample_limit: null
  resume: true  # Auto-resume from previous progress if interrupted

llm:
  llm_provider: "hf"
  model_name: null  # Will use default from hf_parallel.yml
  base_url: "http://localhost:8001"

output:
  # All workers write to the same directory (worker_id included in filename)
  output_dir: "data/extraction_results_parallel"

indexing:
  corpus_name: "medcorp_textbooks"

# Speed optimizations (user selected)
spatial:
  enable_osm_context: false  # Disable OSM context for 10% speedup

reflection:
  enabled: false  # Disable reflection for 2Ã— speedup per document
